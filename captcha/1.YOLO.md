---
id: intro1
permalink: /captcha/m1
title: 'YOLO å…¥é—¨'
---
# YOLO Python å…¥é—¨æŒ‡å—

## ç›®å½•
1. [YOLO ç®€ä»‹](#yolo-ç®€ä»‹)
2. [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
3. [YOLOv8 å¿«é€Ÿå…¥é—¨](#yolov8-å¿«é€Ÿå…¥é—¨)
4. [å›¾åƒç›®æ ‡æ£€æµ‹](#å›¾åƒç›®æ ‡æ£€æµ‹)
5. [è§†é¢‘ç›®æ ‡æ£€æµ‹](#è§†é¢‘ç›®æ ‡æ£€æµ‹)
6. [å®æ—¶æ‘„åƒå¤´æ£€æµ‹](#å®æ—¶æ‘„åƒå¤´æ£€æµ‹)
7. [æ¨¡å‹è®­ç»ƒ](#æ¨¡å‹è®­ç»ƒ)
8. [é«˜çº§åº”ç”¨](#é«˜çº§åº”ç”¨)
9. [å®æˆ˜æ¡ˆä¾‹](#å®æˆ˜æ¡ˆä¾‹)

---

## YOLO ç®€ä»‹

YOLO (You Only Look Once) æ˜¯ä¸€ç§å…ˆè¿›çš„å®æ—¶ç›®æ ‡æ£€æµ‹ç®—æ³•ã€‚å®ƒçš„ä¸»è¦ç‰¹ç‚¹ï¼š

### æ ¸å¿ƒä¼˜åŠ¿
- **é€Ÿåº¦å¿«**: å®æ—¶æ£€æµ‹ï¼Œå¯è¾¾åˆ° 30+ FPS
- **ç²¾åº¦é«˜**: åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¾¾åˆ° SOTA æ°´å¹³
- **æ˜“äºä½¿ç”¨**: API ç®€æ´ï¼Œä¸Šæ‰‹å®¹æ˜“
- **å¤šä»»åŠ¡**: æ”¯æŒæ£€æµ‹ã€åˆ†å‰²ã€åˆ†ç±»ã€å§¿æ€ä¼°è®¡ç­‰

### YOLO ç‰ˆæœ¬æ¼”è¿›
- **YOLOv1-v4**: åŸå§‹ Darknet æ¡†æ¶
- **YOLOv5**: PyTorch å®ç°ï¼Œæ˜“ç”¨æ€§å¼º
- **YOLOv6-v7**: å·¥ä¸šçº§åº”ç”¨ä¼˜åŒ–
- **YOLOv8**: Ultralytics æœ€æ–°ç‰ˆæœ¬ï¼ˆæ¨èï¼‰
- **YOLO11**: 2024 å¹´æœ€æ–°ç‰ˆæœ¬

æœ¬æŒ‡å—ä¸»è¦ä½¿ç”¨ **YOLOv8**ï¼Œå› ä¸ºå®ƒï¼š
- æ–‡æ¡£å®Œå–„ï¼Œç¤¾åŒºæ´»è·ƒ
- ç»Ÿä¸€çš„ API æ¥å£
- æ”¯æŒå¤šç§ä»»åŠ¡ï¼ˆæ£€æµ‹ã€åˆ†å‰²ã€åˆ†ç±»ç­‰ï¼‰
- æ€§èƒ½ä¼˜ç§€

---

## ç¯å¢ƒé…ç½®

### 1. å®‰è£…ä¾èµ–

```bash
# å®‰è£… PyTorchï¼ˆæ ¹æ®ä½ çš„ CUDA ç‰ˆæœ¬é€‰æ‹©ï¼‰
pip install torch torchvision

# å®‰è£… Ultralyticsï¼ˆYOLOv8ï¼‰
pip install ultralytics

# å®‰è£…å…¶ä»–ä¾èµ–
pip install opencv-python numpy matplotlib pillow
```

### 2. éªŒè¯å®‰è£…

```python
from ultralytics import YOLO
import torch

print(f"Ultralytics version: {YOLO.__version__}")
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
```

### 3. GPU é…ç½®ï¼ˆå¯é€‰ï¼‰

```python
import torch

# æ£€æŸ¥ GPU
if torch.cuda.is_available():
    device = torch.device("cuda")
    print(f"Using GPU: {torch.cuda.get_device_name(0)}")
else:
    device = torch.device("cpu")
    print("Using CPU")
```

---

## YOLOv8 å¿«é€Ÿå…¥é—¨

### 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹

```python
from ultralytics import YOLO

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
model = YOLO('yolov8n.pt')  # nano ç‰ˆæœ¬ï¼ˆæœ€å¿«ï¼‰
# model = YOLO('yolov8s.pt')  # small ç‰ˆæœ¬
# model = YOLO('yolov8m.pt')  # medium ç‰ˆæœ¬
# model = YOLO('yolov8l.pt')  # large ç‰ˆæœ¬
# model = YOLO('yolov8x.pt')  # extra large ç‰ˆæœ¬ï¼ˆæœ€å‡†ç¡®ï¼‰
```

### 2. æ¨¡å‹å¤§å°å¯¹æ¯”

| æ¨¡å‹ | å¤§å° | mAP | é€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
|------|------|-----|------|---------|
| YOLOv8n | 3.2M | 37.3 | æœ€å¿« | ç§»åŠ¨ç«¯ã€è¾¹ç¼˜è®¾å¤‡ |
| YOLOv8s | 11.2M | 44.9 | å¿« | å®æ—¶åº”ç”¨ |
| YOLOv8m | 25.9M | 50.2 | ä¸­ç­‰ | é€šç”¨åœºæ™¯ |
| YOLOv8l | 43.7M | 52.9 | æ…¢ | é«˜ç²¾åº¦éœ€æ±‚ |
| YOLOv8x | 68.2M | 53.9 | æœ€æ…¢ | ç¦»çº¿åˆ†æ |

### 3. COCO æ•°æ®é›†ç±»åˆ«

YOLO é¢„è®­ç»ƒæ¨¡å‹åŸºäº COCO æ•°æ®é›†ï¼Œå¯æ£€æµ‹ 80 ç±»ç‰©ä½“ï¼š

```python
# æŸ¥çœ‹æ‰€æœ‰ç±»åˆ«
print(model.names)

# å¸¸è§ç±»åˆ«
# 0: person, 1: bicycle, 2: car, 3: motorcycle, 4: airplane
# 5: bus, 6: train, 7: truck, 8: boat, 9: traffic light
# 16: dog, 17: cat, 18: bird, 39: bottle, 41: cup
# 56: chair, 57: couch, 59: bed, 62: tv, 63: laptop
```

---

## å›¾åƒç›®æ ‡æ£€æµ‹

### 1. åŸºç¡€æ£€æµ‹

```python
from ultralytics import YOLO
import cv2

# åŠ è½½æ¨¡å‹
model = YOLO('yolov8n.pt')

# å¯¹å•å¼ å›¾åƒè¿›è¡Œæ£€æµ‹
results = model('image.jpg')

# æ˜¾ç¤ºç»“æœ
results[0].show()

# ä¿å­˜ç»“æœ
results[0].save('result.jpg')
```

### 2. æ‰¹é‡æ£€æµ‹

```python
# æ£€æµ‹å¤šå¼ å›¾åƒ
results = model(['image1.jpg', 'image2.jpg', 'image3.jpg'])

# éå†ç»“æœ
for i, result in enumerate(results):
    result.save(f'result_{i}.jpg')
```

### 3. æ£€æµ‹æ–‡ä»¶å¤¹

```python
# æ£€æµ‹æ•´ä¸ªæ–‡ä»¶å¤¹
results = model('images/', save=True, save_txt=True)
```

### 4. è¯¦ç»†ç»“æœè§£æ

```python
from ultralytics import YOLO

model = YOLO('yolov8n.pt')
results = model('image.jpg')

# è·å–ç¬¬ä¸€å¼ å›¾åƒçš„ç»“æœ
result = results[0]

# æ£€æµ‹æ¡†ä¿¡æ¯
boxes = result.boxes

# éå†æ¯ä¸ªæ£€æµ‹æ¡†
for box in boxes:
    # è¾¹ç•Œæ¡†åæ ‡ (x1, y1, x2, y2)
    coords = box.xyxy[0].cpu().numpy()
    x1, y1, x2, y2 = coords
    
    # ç½®ä¿¡åº¦
    confidence = box.conf[0].cpu().numpy()
    
    # ç±»åˆ«
    class_id = int(box.cls[0].cpu().numpy())
    class_name = model.names[class_id]
    
    print(f"æ£€æµ‹åˆ°: {class_name}, ç½®ä¿¡åº¦: {confidence:.2f}")
    print(f"ä½ç½®: ({x1:.0f}, {y1:.0f}) -> ({x2:.0f}, {y2:.0f})")
```

### 5. è‡ªå®šä¹‰ç»˜åˆ¶ç»“æœ

```python
import cv2
from ultralytics import YOLO

model = YOLO('yolov8n.pt')
image = cv2.imread('image.jpg')
results = model(image)

# è·å–æ£€æµ‹ç»“æœ
boxes = results[0].boxes

# åœ¨åŸå›¾ä¸Šç»˜åˆ¶
for box in boxes:
    # è·å–åæ ‡
    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
    
    # è·å–ç±»åˆ«å’Œç½®ä¿¡åº¦
    class_id = int(box.cls[0])
    confidence = float(box.conf[0])
    label = f"{model.names[class_id]} {confidence:.2f}"
    
    # ç»˜åˆ¶çŸ©å½¢æ¡†
    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
    
    # ç»˜åˆ¶æ ‡ç­¾
    cv2.putText(image, label, (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

cv2.imshow('Detection', image)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

---

## è§†é¢‘ç›®æ ‡æ£€æµ‹

### 1. åŸºç¡€è§†é¢‘æ£€æµ‹

```python
from ultralytics import YOLO

model = YOLO('yolov8n.pt')

# æ£€æµ‹è§†é¢‘
results = model('video.mp4', save=True)
```

### 2. é€å¸§å¤„ç†è§†é¢‘

```python
import cv2
from ultralytics import YOLO

model = YOLO('yolov8n.pt')
cap = cv2.VideoCapture('video.mp4')

# è·å–è§†é¢‘ä¿¡æ¯
fps = int(cap.get(cv2.CAP_PROP_FPS))
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# åˆ›å»ºè§†é¢‘å†™å…¥å™¨
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('output.mp4', fourcc, fps, (width, height))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # æ£€æµ‹
    results = model(frame)
    
    # è·å–ç»˜åˆ¶åçš„å¸§
    annotated_frame = results[0].plot()
    
    # å†™å…¥è§†é¢‘
    out.write(annotated_frame)
    
    # æ˜¾ç¤º
    cv2.imshow('Detection', annotated_frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
out.release()
cv2.destroyAllWindows()
```

### 3. è·Ÿè¸ªæ¨¡å¼

```python
from ultralytics import YOLO

model = YOLO('yolov8n.pt')

# ä½¿ç”¨è·Ÿè¸ªæ¨¡å¼ï¼ˆä¸ºæ¯ä¸ªå¯¹è±¡åˆ†é… IDï¼‰
results = model.track('video.mp4', save=True)

# æˆ–è€…å®æ—¶è·Ÿè¸ª
cap = cv2.VideoCapture('video.mp4')
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # track æ–¹æ³•ä¼šä¸ºæ¯ä¸ªå¯¹è±¡åˆ†é…å”¯ä¸€ ID
    results = model.track(frame, persist=True)
    annotated_frame = results[0].plot()
    
    cv2.imshow('Tracking', annotated_frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

---

## å®æ—¶æ‘„åƒå¤´æ£€æµ‹

### 1. åŸºç¡€æ‘„åƒå¤´æ£€æµ‹

```python
import cv2
from ultralytics import YOLO

model = YOLO('yolov8n.pt')

# æ‰“å¼€æ‘„åƒå¤´
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # æ£€æµ‹
    results = model(frame)
    
    # æ˜¾ç¤ºç»“æœ
    annotated_frame = results[0].plot()
    cv2.imshow('Webcam Detection', annotated_frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

### 2. ä¼˜åŒ–æ€§èƒ½çš„æ‘„åƒå¤´æ£€æµ‹

```python
import cv2
from ultralytics import YOLO
import time

model = YOLO('yolov8n.pt')
cap = cv2.VideoCapture(0)

# è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨ç‡
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

prev_time = 0

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # æ£€æµ‹ï¼ˆä½¿ç”¨è¾ƒä½çš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼‰
    results = model(frame, conf=0.5)
    
    # è®¡ç®— FPS
    curr_time = time.time()
    fps = 1 / (curr_time - prev_time)
    prev_time = curr_time
    
    # ç»˜åˆ¶ç»“æœ
    annotated_frame = results[0].plot()
    
    # æ˜¾ç¤º FPS
    cv2.putText(annotated_frame, f'FPS: {fps:.1f}', (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    
    cv2.imshow('Webcam Detection', annotated_frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

---

## æ¨¡å‹è®­ç»ƒ

### 1. å‡†å¤‡æ•°æ®é›†

æ•°æ®é›†ç›®å½•ç»“æ„ï¼š
```
dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â””â”€â”€ img2.jpg
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ img3.jpg
â”‚       â””â”€â”€ img4.jpg
â””â”€â”€ labels/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ img1.txt
    â”‚   â””â”€â”€ img2.txt
    â””â”€â”€ val/
        â”œâ”€â”€ img3.txt
        â””â”€â”€ img4.txt
```

æ ‡ç­¾æ ¼å¼ï¼ˆYOLO æ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªå¯¹è±¡ï¼‰ï¼š
```
class_id center_x center_y width height
```
æ‰€æœ‰å€¼éƒ½æ˜¯ç›¸å¯¹äºå›¾åƒå¤§å°çš„å½’ä¸€åŒ–å€¼ï¼ˆ0-1ï¼‰

### 2. åˆ›å»ºæ•°æ®é…ç½®æ–‡ä»¶

åˆ›å»º `data.yaml` æ–‡ä»¶ï¼š
```yaml
# data.yaml
path: /path/to/dataset  # æ•°æ®é›†æ ¹ç›®å½•
train: images/train     # è®­ç»ƒé›†è·¯å¾„
val: images/val         # éªŒè¯é›†è·¯å¾„

# ç±»åˆ«
names:
  0: person
  1: car
  2: dog
```

### 3. è®­ç»ƒæ¨¡å‹

```python
from ultralytics import YOLO

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = YOLO('yolov8n.pt')

# è®­ç»ƒæ¨¡å‹
results = model.train(
    data='data.yaml',      # æ•°æ®é…ç½®æ–‡ä»¶
    epochs=100,            # è®­ç»ƒè½®æ•°
    imgsz=640,            # å›¾åƒå¤§å°
    batch=16,             # æ‰¹æ¬¡å¤§å°
    name='my_model',      # å®éªŒåç§°
    patience=50,          # æ—©åœè€å¿ƒå€¼
    save=True,            # ä¿å­˜æ£€æŸ¥ç‚¹
    device=0              # GPU è®¾å¤‡ï¼ˆ0 æˆ– 'cpu'ï¼‰
)
```

### 4. éªŒè¯æ¨¡å‹

```python
from ultralytics import YOLO

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
model = YOLO('runs/detect/my_model/weights/best.pt')

# éªŒè¯
metrics = model.val()

# æŸ¥çœ‹æŒ‡æ ‡
print(f"mAP50: {metrics.box.map50}")
print(f"mAP50-95: {metrics.box.map}")
```

### 5. å¯¼å‡ºæ¨¡å‹

```python
from ultralytics import YOLO

model = YOLO('best.pt')

# å¯¼å‡ºä¸º ONNX æ ¼å¼
model.export(format='onnx')

# å¯¼å‡ºä¸º TensorRT
model.export(format='engine')

# å¯¼å‡ºä¸º TFLiteï¼ˆç§»åŠ¨ç«¯ï¼‰
model.export(format='tflite')
```

---

## é«˜çº§åº”ç”¨

### 1. è°ƒæ•´æ£€æµ‹å‚æ•°

```python
from ultralytics import YOLO

model = YOLO('yolov8n.pt')

# è‡ªå®šä¹‰å‚æ•°
results = model(
    'image.jpg',
    conf=0.25,           # ç½®ä¿¡åº¦é˜ˆå€¼
    iou=0.7,             # NMS IOU é˜ˆå€¼
    max_det=300,         # æœ€å¤§æ£€æµ‹æ•°é‡
    classes=[0, 2, 3],   # åªæ£€æµ‹ç‰¹å®šç±»åˆ«
    device='cpu',        # ä½¿ç”¨çš„è®¾å¤‡
    verbose=False        # ä¸æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
)
```

### 2. ç‰¹å®šåŒºåŸŸæ£€æµ‹

```python
import cv2
from ultralytics import YOLO
import numpy as np

model = YOLO('yolov8n.pt')
image = cv2.imread('image.jpg')

# å®šä¹‰ ROIï¼ˆæ„Ÿå…´è¶£åŒºåŸŸï¼‰
x1, y1, x2, y2 = 100, 100, 500, 500
roi = image[y1:y2, x1:x2]

# åªæ£€æµ‹ ROI
results = model(roi)

# å°†ç»“æœæ˜ å°„å›åŸå›¾åæ ‡
boxes = results[0].boxes
for box in boxes:
    coords = box.xyxy[0].cpu().numpy()
    # è°ƒæ•´åæ ‡
    coords[0] += x1
    coords[1] += y1
    coords[2] += x1
    coords[3] += y1
```

### 3. è®¡æ•°åº”ç”¨

```python
import cv2
from ultralytics import YOLO
from collections import defaultdict

model = YOLO('yolov8n.pt')
cap = cv2.VideoCapture('video.mp4')

# ç»Ÿè®¡æ¯ç±»ç‰©ä½“æ•°é‡
object_counts = defaultdict(int)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    results = model(frame)
    boxes = results[0].boxes
    
    # é‡ç½®è®¡æ•°
    current_counts = defaultdict(int)
    
    # ç»Ÿè®¡
    for box in boxes:
        class_id = int(box.cls[0])
        class_name = model.names[class_id]
        current_counts[class_name] += 1
    
    # æ˜¾ç¤ºè®¡æ•°
    y_offset = 30
    for obj, count in current_counts.items():
        text = f"{obj}: {count}"
        cv2.putText(frame, text, (10, y_offset),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        y_offset += 30
    
    cv2.imshow('Counting', frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

### 4. æ£€æµ‹çº¿ç©¿è¶Šï¼ˆè·¨çº¿è®¡æ•°ï¼‰

```python
import cv2
from ultralytics import YOLO
import numpy as np

model = YOLO('yolov8n.pt')
cap = cv2.VideoCapture('video.mp4')

# å®šä¹‰æ£€æµ‹çº¿ï¼ˆy åæ ‡ï¼‰
line_y = 300
crossed_ids = set()

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # ä½¿ç”¨è·Ÿè¸ªæ¨¡å¼
    results = model.track(frame, persist=True)
    
    # ç»˜åˆ¶æ£€æµ‹çº¿
    cv2.line(frame, (0, line_y), (frame.shape[1], line_y), 
             (0, 0, 255), 2)
    
    if results[0].boxes.id is not None:
        boxes = results[0].boxes
        track_ids = boxes.id.cpu().numpy().astype(int)
        coords = boxes.xyxy.cpu().numpy()
        
        for track_id, coord in zip(track_ids, coords):
            x1, y1, x2, y2 = coord
            center_y = (y1 + y2) / 2
            
            # æ£€æŸ¥æ˜¯å¦ç©¿è¶Šçº¿
            if center_y > line_y and track_id not in crossed_ids:
                crossed_ids.add(track_id)
    
    # æ˜¾ç¤ºè®¡æ•°
    cv2.putText(frame, f'Crossed: {len(crossed_ids)}', (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    
    cv2.imshow('Line Crossing', frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

---

## å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šå®‰å…¨å¸½æ£€æµ‹

```python
from ultralytics import YOLO
import cv2

# è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹æ£€æµ‹å®‰å…¨å¸½
model = YOLO('yolov8n.pt')

# è®­ç»ƒï¼ˆå‡è®¾ä½ æœ‰æ ‡æ³¨å¥½çš„æ•°æ®ï¼‰
# model.train(data='hardhat.yaml', epochs=100)

# ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹
model = YOLO('hardhat_best.pt')

cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    results = model(frame)
    
    # æ£€æŸ¥æ˜¯å¦ä½©æˆ´å®‰å…¨å¸½
    boxes = results[0].boxes
    has_hardhat = False
    
    for box in boxes:
        class_id = int(box.cls[0])
        if model.names[class_id] == 'hardhat':
            has_hardhat = True
            break
    
    # æ˜¾ç¤ºè­¦å‘Š
    if not has_hardhat:
        cv2.putText(frame, 'WARNING: No Hardhat!', (10, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)
    
    annotated_frame = results[0].plot()
    cv2.imshow('Hardhat Detection', annotated_frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

### æ¡ˆä¾‹2ï¼šè½¦è¾†æ£€æµ‹ä¸é€Ÿåº¦ä¼°ç®—

```python
import cv2
from ultralytics import YOLO
import numpy as np

model = YOLO('yolov8n.pt')
cap = cv2.VideoCapture('traffic.mp4')

# å­˜å‚¨ç‰©ä½“ä½ç½®å†å²
object_history = {}
fps = cap.get(cv2.CAP_PROP_FPS)

# åƒç´ åˆ°ç±³çš„è½¬æ¢å› å­ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µæ ‡å®šï¼‰
pixel_to_meter = 0.05

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    results = model.track(frame, persist=True, classes=[2, 5, 7])  # car, bus, truck
    
    if results[0].boxes.id is not None:
        boxes = results[0].boxes
        track_ids = boxes.id.cpu().numpy().astype(int)
        coords = boxes.xyxy.cpu().numpy()
        
        for track_id, coord in zip(track_ids, coords):
            x1, y1, x2, y2 = coord
            center_x = (x1 + x2) / 2
            center_y = (y1 + y2) / 2
            
            # æ›´æ–°å†å²ä½ç½®
            if track_id not in object_history:
                object_history[track_id] = []
            
            object_history[track_id].append((center_x, center_y))
            
            # ä¿æŒæœ€è¿‘10å¸§
            if len(object_history[track_id]) > 10:
                object_history[track_id].pop(0)
            
            # è®¡ç®—é€Ÿåº¦
            if len(object_history[track_id]) >= 2:
                pos1 = object_history[track_id][-1]
                pos2 = object_history[track_id][-2]
                
                # è®¡ç®—åƒç´ è·ç¦»
                distance_px = np.sqrt((pos1[0] - pos2[0])**2 + 
                                     (pos1[1] - pos2[1])**2)
                
                # è½¬æ¢ä¸ºç±³/ç§’ï¼Œå†è½¬æ¢ä¸ºåƒç±³/å°æ—¶
                distance_m = distance_px * pixel_to_meter
                speed_mps = distance_m * fps
                speed_kmh = speed_mps * 3.6
                
                # æ˜¾ç¤ºé€Ÿåº¦
                cv2.putText(frame, f'{speed_kmh:.1f} km/h', 
                           (int(x1), int(y1) - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    annotated_frame = results[0].plot()
    cv2.imshow('Vehicle Speed', annotated_frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

### æ¡ˆä¾‹3ï¼šå£ç½©æ£€æµ‹

```python
from ultralytics import YOLO
import cv2

# å‡è®¾å·²ç»è®­ç»ƒå¥½å£ç½©æ£€æµ‹æ¨¡å‹
model = YOLO('mask_detection.pt')

cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    results = model(frame)
    boxes = results[0].boxes
    
    for box in boxes:
        class_id = int(box.cls[0])
        class_name = model.names[class_id]
        conf = float(box.conf[0])
        
        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
        
        # æ ¹æ®æ£€æµ‹ç»“æœè®¾ç½®é¢œè‰²
        if class_name == 'with_mask':
            color = (0, 255, 0)  # ç»¿è‰²
            label = f'Mask {conf:.2f}'
        elif class_name == 'without_mask':
            color = (0, 0, 255)  # çº¢è‰²
            label = f'No Mask {conf:.2f}'
        else:
            color = (255, 255, 0)  # é»„è‰²
            label = f'Incorrect {conf:.2f}'
        
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
        cv2.putText(frame, label, (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    
    cv2.imshow('Mask Detection', frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

---

## æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. æ¨¡å‹é€‰æ‹©
```python
# å®æ—¶åº”ç”¨ -> ä½¿ç”¨ nano æˆ– small
model = YOLO('yolov8n.pt')

# é«˜ç²¾åº¦éœ€æ±‚ -> ä½¿ç”¨ large æˆ– extra large
model = YOLO('yolov8x.pt')
```

### 2. å›¾åƒå°ºå¯¸
```python
# è¾ƒå°å›¾åƒ -> æ›´å¿«ä½†ç²¾åº¦ç¨ä½
results = model('image.jpg', imgsz=320)

# æ ‡å‡†å›¾åƒ
results = model('image.jpg', imgsz=640)

# å¤§å›¾åƒ -> æ›´æ…¢ä½†ç²¾åº¦æ›´é«˜
results = model('image.jpg', imgsz=1280)
```

### 3. æ‰¹å¤„ç†
```python
# æ‰¹é‡å¤„ç†å¤šå¼ å›¾åƒ
images = ['img1.jpg', 'img2.jpg', 'img3.jpg']
results = model(images, stream=True)  # ä½¿ç”¨æµå¼å¤„ç†èŠ‚çœå†…å­˜
```

### 4. åŠç²¾åº¦æ¨ç†ï¼ˆGPUï¼‰
```python
model = YOLO('yolov8n.pt')
results = model('image.jpg', half=True)  # ä½¿ç”¨ FP16
```

---

## å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### 1. å†…å­˜ä¸è¶³
```python
# ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
model = YOLO('yolov8n.pt')

# å‡å°æ‰¹æ¬¡å¤§å°
model.train(data='data.yaml', batch=8)

# ä½¿ç”¨æµå¼å¤„ç†
results = model(images, stream=True)
```

### 2. æ£€æµ‹æ•ˆæœä¸ä½³
```python
# è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼
results = model('image.jpg', conf=0.3)

# è°ƒæ•´ IOU é˜ˆå€¼
results = model('image.jpg', iou=0.5)

# ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
model = YOLO('yolov8l.pt')
```

### 3. é€Ÿåº¦å¤ªæ…¢
```python
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
model = YOLO('yolov8n.pt')

# é™ä½å›¾åƒåˆ†è¾¨ç‡
results = model('image.jpg', imgsz=320)

# ä½¿ç”¨ GPU
results = model('image.jpg', device=0)
```

---

## è¿›é˜¶å­¦ä¹ èµ„æº

### å®˜æ–¹èµ„æº
- **Ultralytics æ–‡æ¡£**: https://docs.ultralytics.com/
- **GitHub**: https://github.com/ultralytics/ultralytics
- **è®ºå›**: https://github.com/ultralytics/ultralytics/discussions

### æ•°æ®é›†èµ„æº
- **Roboflow**: https://roboflow.com/ (æ•°æ®é›†ç®¡ç†å’Œå¢å¼º)
- **COCO Dataset**: https://cocodataset.org/
- **Open Images**: https://storage.googleapis.com/openimages/web/index.html

### æ ‡æ³¨å·¥å…·
- **LabelImg**: å›¾åƒæ ‡æ³¨å·¥å…·
- **CVAT**: åœ¨çº¿æ ‡æ³¨å¹³å°
- **Roboflow Annotate**: åœ¨çº¿æ ‡æ³¨

---

## æ€»ç»“

è¿™ä»½æŒ‡å—æ¶µç›–äº† YOLO çš„æ ¸å¿ƒå†…å®¹ï¼š

âœ… **åŸºç¡€çŸ¥è¯†**
- YOLO åŸç†å’Œç‰ˆæœ¬æ¼”è¿›
- ç¯å¢ƒé…ç½®å’Œæ¨¡å‹é€‰æ‹©

âœ… **æ ¸å¿ƒåŠŸèƒ½**
- å›¾åƒã€è§†é¢‘ã€æ‘„åƒå¤´æ£€æµ‹
- ç›®æ ‡è·Ÿè¸ª
- è‡ªå®šä¹‰è®­ç»ƒ

âœ… **å®æˆ˜åº”ç”¨**
- è®¡æ•°ç»Ÿè®¡
- å®‰å…¨ç›‘æ§
- é€Ÿåº¦æ£€æµ‹
- å£ç½©è¯†åˆ«

âœ… **æ€§èƒ½ä¼˜åŒ–**
- æ¨¡å‹é€‰æ‹©ç­–ç•¥
- æ¨ç†åŠ é€ŸæŠ€å·§
- å†…å­˜ç®¡ç†æ–¹æ¡ˆ

é€šè¿‡æœ¬æŒ‡å—ï¼Œä½ å·²ç»æŒæ¡äº†ï¼š
1. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹
2. å¤„ç†å›¾åƒã€è§†é¢‘å’Œå®æ—¶æ‘„åƒå¤´
3. è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹
4. å®ç°å„ç§å®é™…åº”ç”¨åœºæ™¯

ç»§ç»­æ¢ç´¢ YOLO çš„æ›´å¤šå¯èƒ½æ€§ï¼Œæ„å»ºä½ çš„è®¡ç®—æœºè§†è§‰åº”ç”¨ï¼

---

## é™„å½•ï¼šå®Œæ•´ä»£ç ç¤ºä¾‹

### A. å®Œæ•´çš„å®æ—¶æ£€æµ‹ç³»ç»Ÿ

```python
import cv2
from ultralytics import YOLO
import time
from collections import defaultdict

class ObjectDetectionSystem:
    def __init__(self, model_path='yolov8n.pt'):
        """åˆå§‹åŒ–æ£€æµ‹ç³»ç»Ÿ"""
        self.model = YOLO(model_path)
        self.cap = None
        self.is_running = False
        self.detection_stats = defaultdict(int)
        
    def start_camera(self, camera_id=0):
        """å¯åŠ¨æ‘„åƒå¤´"""
        self.cap = cv2.VideoCapture(camera_id)
        if not self.cap.isOpened():
            raise Exception("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        
        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        self.is_running = True
        
    def process_video(self, video_path):
        """å¤„ç†è§†é¢‘æ–‡ä»¶"""
        self.cap = cv2.VideoCapture(video_path)
        if not self.cap.isOpened():
            raise Exception("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
        self.is_running = True
        
    def detect_and_display(self, conf_threshold=0.5, show_stats=True):
        """æ£€æµ‹å¹¶æ˜¾ç¤ºç»“æœ"""
        prev_time = 0
        
        while self.is_running and self.cap.isOpened():
            ret, frame = self.cap.read()
            if not ret:
                break
            
            # æ‰§è¡Œæ£€æµ‹
            results = self.model(frame, conf=conf_threshold, verbose=False)
            
            # ç»Ÿè®¡æ£€æµ‹å¯¹è±¡
            self.detection_stats.clear()
            boxes = results[0].boxes
            
            for box in boxes:
                class_id = int(box.cls[0])
                class_name = self.model.names[class_id]
                self.detection_stats[class_name] += 1
            
            # è·å–æ ‡æ³¨åçš„å¸§
            annotated_frame = results[0].plot()
            
            # è®¡ç®— FPS
            curr_time = time.time()
            fps = 1 / (curr_time - prev_time) if prev_time else 0
            prev_time = curr_time
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            if show_stats:
                self._draw_stats(annotated_frame, fps)
            
            # æ˜¾ç¤ºç»“æœ
            cv2.imshow('YOLO Detection System', annotated_frame)
            
            # æŒ‰é”®æ§åˆ¶
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                # æˆªå›¾
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                cv2.imwrite(f'screenshot_{timestamp}.jpg', annotated_frame)
                print(f"æˆªå›¾å·²ä¿å­˜: screenshot_{timestamp}.jpg")
        
        self.stop()
    
    def _draw_stats(self, frame, fps):
        """ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯"""
        # åˆ›å»ºåŠé€æ˜èƒŒæ™¯
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (300, 150), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
        
        # æ˜¾ç¤º FPS
        cv2.putText(frame, f'FPS: {fps:.1f}', (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # æ˜¾ç¤ºæ£€æµ‹ç»Ÿè®¡
        y_offset = 70
        cv2.putText(frame, 'Detections:', (20, y_offset),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        y_offset += 25
        for obj, count in sorted(self.detection_stats.items()):
            text = f'{obj}: {count}'
            cv2.putText(frame, text, (30, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            y_offset += 20
    
    def stop(self):
        """åœæ­¢æ£€æµ‹ç³»ç»Ÿ"""
        self.is_running = False
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # åˆ›å»ºæ£€æµ‹ç³»ç»Ÿ
    detector = ObjectDetectionSystem('yolov8n.pt')
    
    # å¯åŠ¨æ‘„åƒå¤´æ£€æµ‹
    detector.start_camera(0)
    detector.detect_and_display(conf_threshold=0.5)
    
    # æˆ–å¤„ç†è§†é¢‘æ–‡ä»¶
    # detector.process_video('video.mp4')
    # detector.detect_and_display()
```

### B. è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒå®Œæ•´æµç¨‹

```python
from ultralytics import YOLO
import yaml
import os

class YOLOTrainer:
    def __init__(self, model_size='n'):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        model_size: 'n', 's', 'm', 'l', 'x'
        """
        self.model = YOLO(f'yolov8{model_size}.pt')
        self.model_size = model_size
        
    def create_data_yaml(self, dataset_path, class_names, output_path='data.yaml'):
        """åˆ›å»ºæ•°æ®é…ç½®æ–‡ä»¶"""
        data_config = {
            'path': dataset_path,
            'train': 'images/train',
            'val': 'images/val',
            'test': 'images/test',  # å¯é€‰
            'names': {i: name for i, name in enumerate(class_names)}
        }
        
        with open(output_path, 'w') as f:
            yaml.dump(data_config, f, sort_keys=False)
        
        print(f"æ•°æ®é…ç½®æ–‡ä»¶å·²åˆ›å»º: {output_path}")
        return output_path
    
    def train(self, data_yaml, epochs=100, batch_size=16, img_size=640,
              project='runs/train', name='exp', resume=False):
        """è®­ç»ƒæ¨¡å‹"""
        print(f"å¼€å§‹è®­ç»ƒ YOLOv8{self.model_size} æ¨¡å‹...")
        
        results = self.model.train(
            data=data_yaml,
            epochs=epochs,
            batch=batch_size,
            imgsz=img_size,
            project=project,
            name=name,
            resume=resume,
            patience=50,           # æ—©åœè€å¿ƒå€¼
            save=True,            # ä¿å­˜æ£€æŸ¥ç‚¹
            save_period=10,       # æ¯10è½®ä¿å­˜ä¸€æ¬¡
            cache=False,          # ä¸ç¼“å­˜å›¾åƒåˆ°å†…å­˜
            device=0,             # GPU è®¾å¤‡
            workers=8,            # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
            optimizer='auto',     # ä¼˜åŒ–å™¨
            verbose=True,         # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            seed=0,              # éšæœºç§å­
            deterministic=True,   # ç¡®å®šæ€§è®­ç»ƒ
            single_cls=False,     # å¤šç±»åˆ«
            rect=False,           # çŸ©å½¢è®­ç»ƒ
            cos_lr=False,         # ä½™å¼¦å­¦ä¹ ç‡
            close_mosaic=10,      # æœ€åNè½®å…³é—­é©¬èµ›å…‹å¢å¼º
            amp=True,            # è‡ªåŠ¨æ··åˆç²¾åº¦
        )
        
        print("è®­ç»ƒå®Œæˆï¼")
        return results
    
    def validate(self, model_path, data_yaml):
        """éªŒè¯æ¨¡å‹"""
        model = YOLO(model_path)
        metrics = model.val(data=data_yaml)
        
        print("\néªŒè¯ç»“æœ:")
        print(f"mAP50: {metrics.box.map50:.4f}")
        print(f"mAP50-95: {metrics.box.map:.4f}")
        print(f"Precision: {metrics.box.mp:.4f}")
        print(f"Recall: {metrics.box.mr:.4f}")
        
        return metrics
    
    def export_model(self, model_path, formats=['onnx', 'torchscript']):
        """å¯¼å‡ºæ¨¡å‹åˆ°ä¸åŒæ ¼å¼"""
        model = YOLO(model_path)
        
        for fmt in formats:
            print(f"å¯¼å‡ºä¸º {fmt} æ ¼å¼...")
            model.export(format=fmt)
        
        print("æ¨¡å‹å¯¼å‡ºå®Œæˆï¼")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # 1. åˆ›å»ºè®­ç»ƒå™¨
    trainer = YOLOTrainer(model_size='n')
    
    # 2. åˆ›å»ºæ•°æ®é…ç½®
    dataset_path = '/path/to/your/dataset'
    class_names = ['class1', 'class2', 'class3']
    data_yaml = trainer.create_data_yaml(dataset_path, class_names)
    
    # 3. è®­ç»ƒæ¨¡å‹
    trainer.train(
        data_yaml=data_yaml,
        epochs=100,
        batch_size=16,
        img_size=640,
        name='my_custom_model'
    )
    
    # 4. éªŒè¯æœ€ä½³æ¨¡å‹
    best_model = 'runs/train/my_custom_model/weights/best.pt'
    trainer.validate(best_model, data_yaml)
    
    # 5. å¯¼å‡ºæ¨¡å‹
    trainer.export_model(best_model, formats=['onnx', 'tflite'])
```

### C. æ•°æ®å¢å¼ºå’Œé¢„å¤„ç†å·¥å…·

```python
import cv2
import numpy as np
from pathlib import Path
import albumentations as A
from albumentations.pytorch import ToTensorV2

class DataAugmentation:
    """æ•°æ®å¢å¼ºå·¥å…·ç±»"""
    
    @staticmethod
    def get_training_augmentation():
        """è·å–è®­ç»ƒæ—¶çš„æ•°æ®å¢å¼º"""
        return A.Compose([
            A.RandomResizedCrop(height=640, width=640, scale=(0.8, 1.0)),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.1),
            A.Rotate(limit=15, p=0.5),
            A.RandomBrightnessContrast(p=0.5),
            A.HueSaturationValue(p=0.5),
            A.GaussianBlur(p=0.2),
            A.GaussNoise(p=0.2),
        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))
    
    @staticmethod
    def get_validation_augmentation():
        """è·å–éªŒè¯æ—¶çš„æ•°æ®å¢å¼º"""
        return A.Compose([
            A.Resize(height=640, width=640),
        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))
    
    @staticmethod
    def augment_dataset(input_dir, output_dir, num_augmentations=3):
        """å¢å¼ºæ•´ä¸ªæ•°æ®é›†"""
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        image_dir = input_path / 'images'
        label_dir = input_path / 'labels'
        
        aug_image_dir = output_path / 'images'
        aug_label_dir = output_path / 'labels'
        aug_image_dir.mkdir(exist_ok=True)
        aug_label_dir.mkdir(exist_ok=True)
        
        transform = DataAugmentation.get_training_augmentation()
        
        for img_file in image_dir.glob('*.jpg'):
            # è¯»å–å›¾åƒå’Œæ ‡ç­¾
            image = cv2.imread(str(img_file))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            label_file = label_dir / f"{img_file.stem}.txt"
            if not label_file.exists():
                continue
            
            bboxes, class_labels = DataAugmentation.read_yolo_labels(label_file)
            
            # ä¿å­˜åŸå§‹å›¾åƒ
            cv2.imwrite(str(aug_image_dir / img_file.name), 
                       cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
            DataAugmentation.write_yolo_labels(
                aug_label_dir / label_file.name, bboxes, class_labels)
            
            # ç”Ÿæˆå¢å¼ºå›¾åƒ
            for i in range(num_augmentations):
                try:
                    augmented = transform(
                        image=image, 
                        bboxes=bboxes, 
                        class_labels=class_labels
                    )
                    
                    aug_img = augmented['image']
                    aug_bboxes = augmented['bboxes']
                    aug_labels = augmented['class_labels']
                    
                    # ä¿å­˜å¢å¼ºåçš„å›¾åƒå’Œæ ‡ç­¾
                    aug_name = f"{img_file.stem}_aug{i}{img_file.suffix}"
                    cv2.imwrite(str(aug_image_dir / aug_name),
                               cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))
                    
                    DataAugmentation.write_yolo_labels(
                        aug_label_dir / f"{img_file.stem}_aug{i}.txt",
                        aug_bboxes, aug_labels
                    )
                except Exception as e:
                    print(f"å¢å¼ºå¤±è´¥ {img_file.name}: {e}")
        
        print(f"æ•°æ®å¢å¼ºå®Œæˆï¼è¾“å‡ºç›®å½•: {output_dir}")
    
    @staticmethod
    def read_yolo_labels(label_file):
        """è¯»å– YOLO æ ¼å¼æ ‡ç­¾"""
        bboxes = []
        class_labels = []
        
        with open(label_file, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) == 5:
                    class_id = int(parts[0])
                    bbox = [float(x) for x in parts[1:]]
                    class_labels.append(class_id)
                    bboxes.append(bbox)
        
        return bboxes, class_labels
    
    @staticmethod
    def write_yolo_labels(label_file, bboxes, class_labels):
        """å†™å…¥ YOLO æ ¼å¼æ ‡ç­¾"""
        with open(label_file, 'w') as f:
            for bbox, label in zip(bboxes, class_labels):
                line = f"{label} {' '.join(map(str, bbox))}\n"
                f.write(line)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # å¢å¼ºæ•°æ®é›†
    DataAugmentation.augment_dataset(
        input_dir='original_dataset',
        output_dir='augmented_dataset',
        num_augmentations=5
    )
```

### D. æ¨¡å‹æ€§èƒ½è¯„ä¼°å·¥å…·

```python
import matplotlib.pyplot as plt
from ultralytics import YOLO
import pandas as pd
import seaborn as sns

class ModelEvaluator:
    """æ¨¡å‹è¯„ä¼°å·¥å…·"""
    
    def __init__(self, model_path):
        self.model = YOLO(model_path)
        
    def evaluate_on_dataset(self, data_yaml):
        """åœ¨æ•°æ®é›†ä¸Šè¯„ä¼°æ¨¡å‹"""
        metrics = self.model.val(data=data_yaml)
        return metrics
    
    def plot_confusion_matrix(self, data_yaml, save_path='confusion_matrix.png'):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        from sklearn.metrics import confusion_matrix
        import numpy as np
        
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…é¢„æµ‹ç»“æœè®¡ç®—
        # ç¤ºä¾‹ä»£ç æ¡†æ¶
        print("æ··æ·†çŸ©é˜µå·²ä¿å­˜")
    
    def compare_models(self, model_paths, data_yaml):
        """æ¯”è¾ƒå¤šä¸ªæ¨¡å‹"""
        results = []
        
        for model_path in model_paths:
            model = YOLO(model_path)
            metrics = model.val(data=data_yaml)
            
            results.append({
                'Model': model_path.split('/')[-1],
                'mAP50': metrics.box.map50,
                'mAP50-95': metrics.box.map,
                'Precision': metrics.box.mp,
                'Recall': metrics.box.mr
            })
        
        df = pd.DataFrame(results)
        print(df)
        
        # å¯è§†åŒ–æ¯”è¾ƒ
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        metrics_to_plot = ['mAP50', 'mAP50-95', 'Precision', 'Recall']
        
        for idx, metric in enumerate(metrics_to_plot):
            ax = axes[idx // 2, idx % 2]
            df.plot(x='Model', y=metric, kind='bar', ax=ax, legend=False)
            ax.set_title(metric)
            ax.set_ylabel('Score')
        
        plt.tight_layout()
        plt.savefig('model_comparison.png')
        print("æ¨¡å‹æ¯”è¾ƒå›¾å·²ä¿å­˜")
        
        return df

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    evaluator = ModelEvaluator('best.pt')
    
    # è¯„ä¼°æ¨¡å‹
    metrics = evaluator.evaluate_on_dataset('data.yaml')
    
    # æ¯”è¾ƒå¤šä¸ªæ¨¡å‹
    models = ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt']
    comparison = evaluator.compare_models(models, 'data.yaml')
```

---

## æœ€åçš„è¯

YOLO æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§ä¸”æ˜“äºä½¿ç”¨çš„ç›®æ ‡æ£€æµ‹æ¡†æ¶ã€‚é€šè¿‡æœ¬æŒ‡å—ï¼Œä½ å·²ç»æŒæ¡äº†ä»åŸºç¡€åº”ç”¨åˆ°é«˜çº§å®šåˆ¶çš„å®Œæ•´æŠ€èƒ½ã€‚

### ä¸‹ä¸€æ­¥å»ºè®®

1. **å®è·µé¡¹ç›®**: é€‰æ‹©ä¸€ä¸ªæ„Ÿå…´è¶£çš„åº”ç”¨åœºæ™¯ï¼Œä»æ•°æ®æ”¶é›†åˆ°æ¨¡å‹éƒ¨ç½²å®Œæ•´å®ç°
2. **å‚æ•°è°ƒä¼˜**: æ·±å…¥äº†è§£å„ç§è¶…å‚æ•°å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“
3. **æ¨¡å‹èåˆ**: å°è¯•é›†æˆå¤šä¸ªæ¨¡å‹ä»¥æé«˜æ£€æµ‹ç²¾åº¦
4. **è¾¹ç¼˜éƒ¨ç½²**: å­¦ä¹ å¦‚ä½•å°†æ¨¡å‹éƒ¨ç½²åˆ°ç§»åŠ¨è®¾å¤‡æˆ–åµŒå…¥å¼ç³»ç»Ÿ

ç¥ä½ åœ¨è®¡ç®—æœºè§†è§‰çš„é“è·¯ä¸Šè¶Šèµ°è¶Šè¿œï¼ğŸš€